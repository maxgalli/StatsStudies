{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\psi(2S)$ Discovery with CMS OpenData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise uses the CMS public data from the 2010 proton-proton run. In particular, the invariant mass spectrum of muon pairs from data is provided. The purpose of the session is to approach the discovery of a \"new\" particle in the context of the observation of the ψ(2S) resonance in the CMS data.\n",
    "\n",
    "This is what the distribution of the dimuon invariant mass spectrum looks like with about 2% of the total 2010 statistics:\n",
    "\n",
    "<img src=\"images/Exercise0_data.png\" alt=\"data_lowstat\" width=\"500\"/>\n",
    "\n",
    "The J/ψ is of course very visible around the 3.1 GeV mass point. We expect to see an excess around 3.65 GeV for the ψ(2S). Is it there? Let's investigate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "In this project you are provided with two datasets, ```DataSet_lowstat.pkl``` and ```DataSet.pkl```, which both refer to the invariant mass of a muon-antimuon pair. The difference bitween the two is that ```DataSet_lowstat.pkl``` corresponds to about 20\\% of the statistics available in 2010, while ```DataSet.pkl``` contains the full statistics. You will be asked to use the low statistics sample in tasks 0, 1 and the full statistics sample in tasks 2, 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "In this part you are required to define the model (i.e. the total PDF) and fit it to the invariant mass distribution contained in ```DataSet_lowstat.pkl```. Here are some tips:\n",
    "\n",
    "- the observable can be fit in a range of [2, 6] GeV\n",
    "- to model the J/ψ peak you can use a Crystal Ball distribution with the following values for the parameters (starting value, [low limit, high limit]): mean (3.1, [2.8, 3.4]), sigma (0.3, [0.0001, 1]), alpha (1.5, [-5, 5]), n (1.5, [0.5, 10])\n",
    "- to model the ψ(2S) peak you can use anothe Crystal Ball distribution with the following values for the parameters: mean (3.7, [2.5, 3.95]) and sigma, alpha, n like the J/ψ\n",
    "- to model the background you can use a Chebychev polynomal of order 3, with the first three coefficients having the followin values: a1 (-0.7, [-2, 2]), a2 (0.3, [-2, 2]), a3 (-0.03, [-2, 2])\n",
    "\n",
    "For each of these components, you then need to define a parameter to describe the yield (number of events). Note that since our **Parameter of Interest** is the ψ(2S) **cross section**, rather than the simple number of events, it is convenient to define the latter as a function of the former:\n",
    "\n",
    "$$N_{\\psi(2S)} = \\epsilon_{\\mu\\mu} \\cdot \\ell \\cdot \\sigma_{\\psi(2S)}$$\n",
    "\n",
    "where efficiency and luminosity will be set constant to 75\\% and 0.64 inverse pb respectively.\n",
    "\n",
    "For yields and cross section you can use the following (starting value, [low limit, high limit]):\n",
    "\n",
    "- J/ψ yield (1500, [0, 10000])\n",
    "- ψ(2S) cross section (3, [0, 40])\n",
    "- background yield (5000, [0, 50000])\n",
    "\n",
    "After running the fit and plotting model and distribution, you should obtain something like the following:\n",
    "\n",
    "<img src=\"images/Exercise0.png\" alt=\"data\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "In this part you are required to compute the **excess significance** of our ψ(2S) in units of sigma. What you will see, given the low statistics of the sample, is that the number of sigmas is way too low to claim a discovery of the ψ(2S) resonance.\n",
    "\n",
    "What happens in these cases is that we set an **upper limit** for our POI (the ψ(2S) cross section) following the prescription described in the [paper](https://arxiv.org/abs/1007.1727?context=hep-ex) *Asymptotic formulae for likelihood-based tests of new physics*. \n",
    "\n",
    "The upper limit found with this prescription can be visualized like the following\n",
    "\n",
    "<img src=\"images/Exercise3.png\" alt=\"ex2\" width=\"500\"/>\n",
    "\n",
    "where the actual value can be found by reading the x-axis value for the point in which the red line (0.05 significance) crosses the black line with red dots.\n",
    "\n",
    "Now, this might sound scary and overwhelming, but since this is a common practice in HEP there are of course tools that already perform these operations. We will talk about them at the end of the explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "It is now time to use the full statistics dataset ```DataSet.pkl```. Remember that in this case the luminosity is 37 inverse pb, while everything else in the model that you previously defined can remain the same.\n",
    "\n",
    "In this case, the excess significance is enough to claim a discovery (you can perform the same operation you did in Task2), so we want to provide a **confidence interval** for our POI. To do so, we can use the **profile likelihood ratio** defined by\n",
    "\n",
    "$$\\lambda(\\mu)=\\frac{L(\\mu, \\hat{\\hat{\\theta}})}{L(\\hat{\\mu}, \\hat{\\theta})}$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\mu$ is the value we are testing (ψ(2S) cross section);\n",
    "- $\\hat{\\hat{\\theta}}$ is the best fit of the nuisance parameters once the $\\mu$ we want to test is fixed;\n",
    "- $\\hat{\\mu}$ and $\\hat{\\theta}$ are the best fit values for $\\mu$ and $\\theta$ when both are left floating in the likelihood.\n",
    "\n",
    "If you perform a *scan* of the POI and plot the value of $-2\\lambda(\\mu)$ you can produce a plot like the following:\n",
    "\n",
    "<img src=\"images/Exercise4.png\" alt=\"ex3\" width=\"500\"/>\n",
    "\n",
    "where the **68\\% CL interval** is given by the points at which $-2\\lambda(\\mu)$ is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "In this last task, we introduce a **systematic uncertainty** and we investigate how this affects the final result. Let's assume we have 10\\% uncertainty on the signal efficiency for which we assume a Gaussian behavior. In your model you will have to rewrite the efficiency as \n",
    "$$\\epsilon = \\kappa \\cdot \\epsilon$$\n",
    "and insert a Gaussian constraint for $\\kappa$.\n",
    "\n",
    "After deriving also in this case 68\\% CL interval you should see something like the following:\n",
    "\n",
    "<img src=\"images/Exercise5.png\" alt=\"ex4\" width=\"500\"/>\n",
    "\n",
    "in line with the fact that the systematic uncertainty that we introduced increases the size of the CL we found for the POI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zfit\n",
    "\n",
    "You might try to perform all the tasks *by hand*, but this will probably require a lot of time! \n",
    "Instead, we suggest to use [zfit](https://zfit.readthedocs.io/en/latest/) and its [tutorials](https://github.com/zfit/zfit-tutorials), where you should find pretty much everything you need. In particular, you might want to take a look at [this notebook](https://github.com/zfit/zfit-tutorials/blob/master/guides/constraints_simultaneous_fit_discovery_splot.ipynb) to get the results required in Task 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('stats-studies')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "977b4b0500dc0f1eeb396653a2d6a006779ae18ccfac5cdd518020df4f07322a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
